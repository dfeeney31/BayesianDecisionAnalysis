group_by(StepNo) %>%
mutate(diff = c(diff(force)))
diffToLace
plot(diffToLace$StepNo, diffToLace$diff)
rm(list=ls())
library(ggplot2)
hikeDat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Hike Work Research/Data/HikeKineticsR.csv')
names(hikeDat)[1] <- 'Subject'
#### Force data alone ###
fDat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Hike Work Research/Data/TMHike/allCondHike.csv')
dh <- subset(fDat, fDat$TrialNo == 'down')
dh <- subset(dh, dh$StepLen > 550) #Filtering out two erroneously short steps
uphill <- subset(fDat, fDat$TrialNo == 'up')
ggplot(data = dh, aes(x=dh$SubName, y = StepLen) + fill = dh$Config) + geom_boxplot() +
geom_point() + theme_bw(base_size = 16) + xlab('Config') +
ylab('Stance Time (ms) DH') + labs(fill = 'Configuration')
ggplot(data = dh, aes(x=dh$SubName, y = StepLen + fill = dh$Config)) + geom_boxplot() +
geom_point() + theme_bw(base_size = 16) + xlab('Config') +
ylab('Stance Time (ms) DH') + labs(fill = 'Configuration')
ggplot(data = dh, aes(x=as.factor(Config), y = StepLen)) + geom_boxplot() +
geom_point() + theme_bw(base_size = 16) + xlab('Config') +
ylab('Stance Time (ms) DH') + labs(fill = 'Configuration')
#### Force data alone ###
fDat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Hike Work Research/Data/TMHike/allCondHike.csv')
dh <- subset(fDat, fDat$TrialNo == 'down')
dh <- subset(dh, dh$StepLen > 550) #Filtering out two erroneously short steps
uphill <- subset(fDat, fDat$TrialNo == 'up')
View(dh)
ggplot(data = dat, aes(x=dh$SubName, y = dh$LoadRate, fill = factor(dh$Config))) + geom_boxplot() +
geom_point(position=position_jitterdodge(),alpha=0.3) + theme_bw(base_size = 16) + xlab('Configuration') +
ylab('Distance') + labs(fill = 'Subject')
ggplot(data = dh, aes(x=dh$SubName, y = dh$LoadRate, fill = factor(dh$Config))) + geom_boxplot() +
geom_point(position=position_jitterdodge(),alpha=0.3) + theme_bw(base_size = 16) + xlab('Configuration') +
ylab('Distance') + labs(fill = 'Subject')
ggplot(data = dh, aes(x=SubName, y = StepLen, fill = factor(Config))) + geom_boxplot() +
geom_point(position=position_jitterdodge(),alpha=0.3) + theme_bw(base_size = 16) + xlab('Configuration') +
ylab('Stance Time Uphill') + labs(fill = 'Subject')
ggplot(data = uphill, aes(x=SubName, y = LoadRate, fill = factor(Config))) + geom_boxplot() +
geom_point(position=position_jitterdodge(),alpha=0.3) + theme_bw(base_size = 16) + xlab('Configuration') +
ylab('Loading Rate Uphill') + labs(fill = 'Subject')
ggplot(data = dh, aes(x=SubName, y = LoadRate, fill = factor(Config))) + geom_boxplot() +
geom_point(position=position_jitterdodge(),alpha=0.3) + theme_bw(base_size = 16) + xlab('Configuration') +
ylab('Loading Rate Downhill') + labs(fill = 'Subject')
ggplot(data = uphill, aes(x=SubName, y = LoadRate, fill = factor(Config))) + geom_boxplot() +
geom_point(position=position_jitterdodge(),alpha=0.3) + theme_bw(base_size = 16) + xlab('Configuration') +
ylab('Loading Rate Uphill') + labs(fill = 'Subject')
ggplot(data = dh, aes(x=SubName, y = LoadRate, fill = factor(Config))) + geom_boxplot() +
geom_point(position=position_jitterdodge(),alpha=0.3) + theme_bw(base_size = 16) + xlab('Configuration') +
ylab('Loading Rate Downhill') + labs(fill = 'Subject')
ggplot(data = uphill, aes(x=SubName, y = StepLen, fill = factor(Config))) + geom_boxplot() +
geom_point(position=position_jitterdodge(),alpha=0.3) + theme_bw(base_size = 16) + xlab('Configuration') +
ylab('Stance Time Uphill') + labs(fill = 'Subject')
uphill <- subset(uphill, uphill$StepLen > 200)
ggplot(data = uphill, aes(x=SubName, y = StepLen, fill = factor(Config))) + geom_boxplot() +
geom_point(position=position_jitterdodge(),alpha=0.3) + theme_bw(base_size = 16) + xlab('Configuration') +
ylab('Stance Time Uphill') + labs(fill = 'Subject')
ggplot(data = dh, aes(x=SubName, y = StepLen, fill = factor(Config))) + geom_boxplot() +
geom_point(position=position_jitterdodge(),alpha=0.3) + theme_bw(base_size = 16) + xlab('Configuration') +
ylab('Stance Time Downhill') + labs(fill = 'Subject')
ggplot(data = uphill, aes(x=SubName, y = brakeImpulse, fill = factor(Config))) + geom_boxplot() +
geom_point(position=position_jitterdodge(),alpha=0.3) + theme_bw(base_size = 16) + xlab('Configuration') +
ylab('Braking Impulse Uphill') + labs(fill = 'Subject')
ggplot(data = dh, aes(x=SubName, y = brakeImpulse, fill = factor(Config))) + geom_boxplot() +
geom_point(position=position_jitterdodge(),alpha=0.3) + theme_bw(base_size = 16) + xlab('Configuration') +
ylab('Braking Impulse Downhill') + labs(fill = 'Subject')
rm(list=ls())
library(ggplot2)
library(lme4)
library(tidyr)
library(dplyr)
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Hike Work Research/Data/NovelData/hikeLong.csv')
bv <- subset(dat, dat$SubName == 'BV')
## outlier removal
remove_outliers <- function(x, na.rm = TRUE, ...) {
qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
H <- 1.5 * IQR(x, na.rm = na.rm)
y <- x
y[x < (qnt[1] - H)] <- NA
y[x > (qnt[2] + H)] <- NA
y
}
dt2 <- dat %>%
group_by(dat$SubName) %>%
mutate(FTI = remove_outliers(FTI))
dt2 <- na.omit(dt2)
## look where differences is greatest between steps ##
bv <- subset(bv, bv$StepNo <= 24)
bv <- subset(bv, bv$Config != 'SD')
bv$X
diffToLace <- bv %>%
arrange(StepNo, Config) %>%
group_by(StepNo) %>%
mutate(diff = c(diff(bv$X)))
diffToLace
## look where differences is greatest between steps ##
bv <- subset(bv, bv$StepNo <= 24)
bv <- subset(bv, bv$Config != 'SD')
diffToLace <- bv %>%
arrange(StepNo, Config) %>%
group_by(StepNo) %>%
mutate(diff = c(diff(X)))
plot(diffToLace$StepNo, diffToLace$diff)
diffToLace
diffToLace <- subset(diffToLace$diff < 50)
diffToLace <- subset(diffToLace, diffToLace$diff < 50)
plot(diffToLace$StepNo, diffToLace$diff)
abline(h=0, col="blue")
####### Script to predict brand awareness based on country, sex, salary, and year ######
rm(list=ls())
library(ggplot2)
library(lme4)
library(qualtRics)
library(tidyr)
library(plyr)
dat<- read_survey("C:/Users/Daniel.Feeney/Dropbox (Boa)/BrandAwareness/BOAYearFixed.csv")
new_vec <- numeric(20404)
for (i in 1:length(dat$Q3.2_1)){
if (is.na(dat$Q3.2_1[i])){
new_vec[i] = 0
} else {
new_vec[i] = 1
}
}
dat$knowBOA <- as.factor(new_vec)
new_vec2 <- numeric(20404)
for (i in 1:length(dat$NEWYEAR)){
if (dat$NEWYEAR[i] == 2){
new_vec2[i] = 0
} else {
new_vec2[i] = 1
}
}
dat$newdate <- new_vec2
# how many responses
sum(dat$newdate == 1)
sum(dat$newdate == 0)
## hiking data
rm(list=ls())
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Hike Work Research/OutdoorProtocolMarch2020/masterResults.csv')
dat$RateNorm <- (dat$RateTotal / 9.81) / 70
up <- subset(dat, dat$UpDown == 'up')
down <- subset(dat, dat$UpDown == 'down')
head(up)
down %>%
group_by(Subject, Config, PrePost) %>%
summarize(
AvgRate = mean(RateNorm),
AvgPkHeel = mean(PkHeel),
AvgHeelImp = mean(HeelImpulse),
AvgStance = mean(stanceTime)
)
library(tidyverse)
down %>%
group_by(Subject, Config, PrePost) %>%
summarize(
AvgRate = mean(RateNorm),
AvgPkHeel = mean(PkHeel),
AvgHeelImp = mean(HeelImpulse),
AvgStance = mean(stanceTime)
)
## hiking data
rm(list=ls())
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Hike Work Research/OutdoorProtocolMarch2020/masterResults.csv')
dat$RateNorm <- (dat$RateTotal / 9.81) / 70
up <- subset(dat, dat$UpDown == 'up')
down <- subset(dat, dat$UpDown == 'down')
head(up)
down %>%
group_by(Subject, Config, PrePost) %>%
summarize(
AvgRate = mean(RateNorm),
AvgPkHeel = mean(PkHeel),
AvgHeelImp = mean(HeelImpulse),
AvgStance = mean(stanceTime)
)
down %>%
group_by(Subject, Config, PrePost) %>%
summarize(
AvgRate = mean(RateNorm),
AvgPkHeel = mean(PkHeel),
AvgHeelImp = mean(HeelImpulse),
AvgStance = mean(stanceTime)
) %>%
ggplot(mapping = aes(PrePost, y = AvgRate, fill = Config)) +
geom_bar(position = "dodge", stat = "identity") + facet_wrap(~ Subject)
#### Analyzing loadsol running data###
rm(list=ls())
library(tidyverse)
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Endurance Protocol Trail Run/Outdoor_Protocol_March2020/Master.csv')
dat$RateNorm <- (dat$RateTotal / 9.81) / 70
dat <- as_tibble(dat)
dat$PrePost <- factor(dat$PrePost, c('pre','post')) #reorder factors to plot pre before post
dat %>%
group_by(Subject, PrePost, Config) %>%
summarize(
AvgRate = mean(RateNorm),
StanceT = mean(stanceTime),
Impulse = mean(ImpulseTotal),
ImpulseHeel = mean(HeelImpulse)
) %>%
ggplot(mapping = aes(x = PrePost, y = AvgRate, fill = Config)) +
geom_bar(position="dodge", stat="identity")+ facet_wrap(~ Subject)
#### Analyzing loadsol running data###
rm(list=ls())
library(tidyverse)
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Endurance Protocol Trail Run/Outdoor_Protocol_March2020/Master.csv')
dat$RateNorm <- (dat$RateTotal / 9.81) / 70
dat <- as_tibble(dat)
dat$PrePost <- factor(dat$PrePost, c('pre','post')) #reorder factors to plot pre before post
dat %>%
group_by(Subject, PrePost, Config) %>%
summarize(
AvgRate = mean(RateNorm),
StanceT = mean(stanceTime),
Impulse = mean(ImpulseTotal),
ImpulseHeel = mean(HeelImpulse)
) %>%
ggplot(mapping = aes(x = PrePost, y = AvgRate, fill = Config)) +
geom_bar(position="dodge", stat="identity")+ facet_wrap(~ Subject)
ggplot(data = dat, mapping = aes(x = PrePost, y = RateNorm, fill = Config)) +
geom_boxplot() + facet_wrap(~ Subject)
## hiking data
rm(list=ls())
library(tidyverse)
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Hike Work Research/OutdoorProtocolMarch2020/masterResults.csv')
dat$RateNorm <- (dat$RateTotal / 9.81) / 70
dat$PrePost <- factor(dat$PrePost, c('pre','post')) #reorder factors to plot pre before post
up <- subset(dat, dat$UpDown == 'up')
down <- subset(dat, dat$UpDown == 'down')
head(up)
down %>%
group_by(Subject, Config, PrePost) %>%
summarize(
AvgRate = mean(RateNorm),
AvgPkHeel = mean(PkHeel),
AvgHeelImp = mean(HeelImpulse),
AvgStance = mean(stanceTime)
) %>%
ggplot(mapping = aes(PrePost, y = AvgRate, fill = Config)) +
geom_bar(position = "dodge", stat = "identity") + facet_wrap(~ Subject)
#### Analyzing loadsol running data###
rm(list=ls())
library(tidyverse)
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Endurance Protocol Trail Run/Outdoor_Protocol_March2020/Master.csv')
dat$RateNorm <- (dat$RateTotal / 9.81) / 70
dat <- as_tibble(dat)
dat$PrePost <- factor(dat$PrePost, c('pre','post')) #reorder factors to plot pre before post
dat %>%
group_by(Subject, PrePost, Config) %>%
summarize(
AvgRate = mean(RateNorm),
StanceT = mean(stanceTime),
Impulse = mean(ImpulseTotal),
ImpulseHeel = mean(HeelImpulse)
) %>%
ggplot(mapping = aes(x = PrePost, y = AvgRate, fill = Config)) +
geom_bar(position="dodge", stat="identity")+ facet_wrap(~ Subject)
## hiking data
rm(list=ls())
library(tidyverse)
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Hike Work Research/OutdoorProtocolMarch2020/masterResults.csv')
dat$RateNorm <- (dat$RateTotal / 9.81) / 70
dat$PrePost <- factor(dat$PrePost, c('pre','post')) #reorder factors to plot pre before post
up <- subset(dat, dat$UpDown == 'up')
down <- subset(dat, dat$UpDown == 'down')
head(up)
down %>%
group_by(Subject, Config, PrePost) %>%
summarize(
AvgRate = mean(RateNorm),
AvgPkHeel = mean(PkHeel),
AvgHeelImp = mean(HeelImpulse),
AvgStance = mean(stanceTime)
) %>%
ggplot(mapping = aes(PrePost, y = AvgRate, fill = Config)) +
geom_bar(position = "dodge", stat = "identity") + facet_wrap(~ Subject)
up %>%
group_by(Subject, Config, PrePost) %>%
summarize(
AvgRate = mean(RateNorm),
AvgPkHeel = mean(PkHeel),
AvgHeelImp = mean(HeelImpulse),
AvgStance = mean(stanceTime)
) %>%
ggplot(mapping = aes(PrePost, y = AvgRate, fill = Config)) +
geom_bar(position = "dodge", stat = "identity") + facet_wrap(~ Subject)
up %>%
group_by(Subject, Config, PrePost) %>%
summarize(
AvgRate = mean(RateNorm),
AvgPkHeel = mean(PkHeel),
AvgHeelImp = mean(HeelImpulse),
AvgStance = mean(stanceTime)
) #%>%
down %>%
group_by(Subject, Config, PrePost) %>%
summarize(
AvgRate = mean(RateNorm),
AvgPkHeel = mean(PkHeel),
AvgHeelImp = mean(HeelImpulse),
AvgStance = mean(stanceTime)
) #%>%
# expected increase in loading rate in lace, however SH had a substantial change in contact time,
# suggesting he may have changed his strategy. Regardless, there was a substantial incresae in loading rate
# between pre and post on the lace day that was not observed on the DD day.
down %>%
group_by(Subject, Config, PrePost) %>%
summarize(
AvgRate = mean(RateNorm),
AvgPkHeel = mean(PkHeel),
AvgHeelImp = mean(HeelImpulse),
AvgStance = mean(stanceTime)
) %>%
ggplot(mapping = aes(PrePost, y = AvgRate, fill = Config)) +
geom_bar(position = "dodge", stat = "identity") + facet_wrap(~ Subject)
rm(list=ls())
# step 1: initialize values of p
p <- runif(1,0,1)
set.seed(5280)
# step 1: initialize values of p
p <- runif(1,0,1)
# step 2, propose new value of p, p'
p_prime <- p + runif(1,-0.05, 0.05)
# Compute the acceptance probability of this new value for the parameter.
# We have to check if the new value improves the posterior probability given our data. This can be seen as the ratio: Pr(pâ€™|h) / Pr(p|h).
likelihood <- function(h, n, p){
lh <- dbinom(h, n, p)
lh
}
# Pr(p) is prior and must lay between 0 and 1. Can use a beta distribution for a flat prior (flat between 0 and 1)
dbeta(p,0,1)
# Pr(p) is prior and must lay between 0 and 1. Can use a beta distribution for a flat prior (flat between 0 and 1)
dbeta(p,1,1)
help dbinom
?dbinom
?dbeta
R <- likelihood(h,n,p_prime)/likelihood(h,n,p) * (dbeta(p_prime,1,1)/dbeta(p,1,1))
### example ###
# Set the numer of tosses.
n <- 100
# Define our likelihood function.
# Since our model is a binomial model, we can use:
likelihood <- function(h,n,p){
lh <- dbinom(h,n,p)
lh
}
# Set the starting value of p
p <- runif(1,0,1)
# Set the number of heads obtained.
h <- 73
# Create an empty data.frame to store the accepted p values for each iteration.
# Remember: "the posterior probability is just an updated version of the prior"
posterior <- data.frame()
# Set the lenght of the loop (Marcov Chain, number of iterations).
nrep <- 5000
# Start the loop (MCMC)
for (i in 1:nrep) {
# Obtain a new proposal value for p
p_prime <- p + runif(1, -0.05,0.05)
# Avoid values out of the range 0 - 1
if (p_prime < 0) {p_prime <- abs(p_prime)}
if (p_prime > 1) {p_prime <- 2 - p_prime}
# Compute the acceptance proability using our likelihood function and the
# beta(1,1) distribution as our prior probability.
R <- likelihood(h,n,p_prime)/likelihood(h,n,p) * (dbeta(p_prime,1,1)/dbeta(p,1,1))
# Accept or reject the new value of p
if (R > 1) {R <- 1}
random <- runif (1,0,1)
if (random < R) {
p <- p_prime
}
# Store the likelihood of the accepted p and its value
posterior[i,1] <- log(likelihood(h, n, p))
posterior[i,2] <- p
print(i)
}
par(mfrow= c(1,2))
prior <- rbeta(5000, 1,1)
plot(1:5000 ,posterior$V2, cex=0, xlab = "generations", ylab = "p",
main = "trace of MCMC\n accepted values of parameter p\n prior = beta(1,1) generations = 5000")
lines(1:5000, posterior$V2, cex=0)
abline(h=mean(posterior$V2), col="red")
plot(density(posterior$V2), xlim = c(min(min(prior),min((posterior$V2))), max(max(prior),max((posterior$V2)))),
ylim = c(0, max(max(density(prior)$y),max((density(posterior$V2)$y)))), main= "prior VS posterior\n prior= beta(1,1)",
lwd=3, col="red")
lines(density(prior), lwd=3, lty=2, col="blue")
legend("topleft", legend=c("prior density","posterior density"),
col=c("blue","red"), lty=c(3,1), lwd=c(3,3), cex = 1)
rm(list=ls())
set.seed(5280)
# Number of random draws from the prior
n_draws <- 10000
prior <- runif(1,0,1) # Here you sample n_draws draws from the prior
hist(prior) # It's always good to eyeball the prior to make sure it looks ok
par(mfrow=c(1,1))
# Number of random draws from the prior
n_draws <- 10000
prior <- runif(1,0,1) # Here you sample n_draws draws from the prior
hist(prior) # It's always good to eyeball the prior to make sure it looks ok
# Number of random draws from the prior
n_draws <- 10000
prior <- runif(n_draw,0,1) # Here you sample n_draws draws from the prior
hist(prior) # It's always good to eyeball the prior to make sure it looks ok
prior <- runif(n_draws,0,1) # Here you sample n_draws draws from the prior
hist(prior) # It's always good to eyeball the prior to make sure it looks ok
# Here you define the generative model
# Defining the generative model
gen_model <- function(rate) {
subscribers <- rbinom(1, size = 16, prob = rate)
subscribers
}
# Here you simulate data using the parameters from the prior and the
# generative model
sim_data <- rep(NA, n_draws)
for(i in 1:n_draws) {
sim_data[i] <- generative_model(prior[i])
}
hist(sim_data)
for(i in 1:n_draws) {
sim_data[i] <- gen_model(prior[i])
}
hist(sim_data)
###  Bayesian A testing example ###
observed_data <- 6 #6 of 16 people responded yes
#filter data that matches observed data
posterior <- prior[sim_data == observed_data]
hist(posterior)
# Now you can summarize the posterior, where a common summary is to take the mean
# or the median posterior, and perhaps a 95% quantile interval.
median(posterior)
quantile(posterior, c(0.025, 0.975))
?rbinom
hist(prior) # It's always good to eyeball the prior to make sure it looks ok
?dbeta
prior2 <- dbeta(n_draws, 3,25)
hist(prior2)
prior2 <- dbeta(n_draws, 3,5)
hist(prior) # It's always good to eyeball the prior to make sure it looks ok
hist(prior2)
?dbeta
x <- seq(0,1,n_draws)
prior2 <- dbeta(x, 3,5)
hist(prior2)
?dbeta
x <- seq(0,1,length = n_draws)
prior2 <- dbeta(x, 3,5)
hist(prior2)
prior2 <- dbeta(x, 3,25)
hist(prior2)
prior2 <- dbeta(x, 3,15)
hist(prior) # It's always good to eyeball the prior to make sure it looks ok
hist(prior2)
hist(prior) # It's always good to eyeball the prior to make sure it looks ok
plot(x, dbeta(x,3,5), ylab = "density", type='l', col=4)
prior2 <- dbeta(x, 3,5)
# Here you simulate data using the parameters from the prior and the
# generative model
sim_data <- rep(NA, n_draws)
sim_data2 <- rep(NA, n_draws)
for(i in 1:n_draws) {
sim_data[i] <- gen_model(prior[i])
sim_data2[i] <- gen_model(prior2[i])
}
hist(sim_data)
hist(sim_data2)
#filter data that matches observed data
posterior <- prior[sim_data == observed_data && sim_data2 == observed_data2]
# Now you can summarize the posterior, where a common summary is to take the mean
# or the median posterior, and perhaps a 95% quantile interval.
median(posterior)
quantile(posterior, c(0.025, 0.975))
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
################################
library("rstan")
setwd('C:/Users/Daniel.Feeney/Documents/BayesianDecisionAnalysis')
data_list <- list(nA = 16, nB = 16, sA = 6, sB = 10)
# Compiling and producing posterior samples from the model.
stan_samples <- stan(file = 'swedishfish.stan', data = data_list)
# Plotting and summarizing the posterior distribution
stan_samples
traceplot(stan_samples)
plot(stan_samples)
# Export the samples to a data.frame for easier handling.
posterior <- as.data.frame(stan_samples)
sum(posterior$rate_diff > 0) / length(posterior$rate_diff)
# Compiling and producing posterior samples from the model.
stan_samples <- stan(file = 'swedishfish.stan', data = data_list)
# Plotting and summarizing the posterior distribution
plot(stan_samples)
# Export the samples to a data.frame for easier handling.
posterior <- as.data.frame(stan_samples)
sum(posterior$rate_diff > 0) / length(posterior$rate_diff)
# calculating the estimated posterior profit using method A (or B)
# a cost of 30 kr + the average profit per sent out add
profitA <- -30 + posterior$rateA * 1000
profitB <- -300 + posterior$rateB * 1000
hist(profitA)
HIST(profitB)
hist(profitA - profitB)
expected_profit_diff <- mean(profitA - profitB)
abline(v = expected_profit_diff, col = "red", lwd =2)
rm(list=ls())
library('tidyverse')
library('rstan')
library('recipes')
install.packages('recipes')
library('recipes')
data("Duncan", package = "carData")
duncan_lm <- lm(prestige ~ type + income + education, data = Duncan)
duncan_lm$coefficients
plot(Duncan$prestige, duncan_lm$fitted.values)
