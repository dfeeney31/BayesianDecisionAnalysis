instlal.packages('rstanarm')
install.packages('rstanarm')
library(rstanarm)
params <- runmod %>%
spread_draws(b_ConfigLace, sigma) %>%
posterior_interval(runmod, prob = 0.9)
posterior_summary(runmod)
posterior_samples(runmod)
posterior <- posterior_samples(runmod)
sum(posterior$b_ConfigLace > 0)
sum(posterior$b_ConfigLace > 0) / length(posterior$b_ConfigLace)
mean(posterior$b_ConfigLace)
dat %>%
group_by(Subject, PrePost, Config) %>%
summarize(
AvgRate = mean(RateNorm),
StanceT = mean(stanceTime),
Impulse = mean(ImpulseTotal),
ImpulseHeel = mean(HeelImpulse)
) %>%
ggplot(mapping = aes(x = PrePost, y = AvgRate, fill = Config)) +
geom_bar(position="dodge", stat="identity")+ facet_wrap(~ Subject)
#### Analyzing loadsol running data###
rm(list=ls())
library(tidyverse)
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Endurance Protocol Trail Run/Outdoor_Protocol_March2020/Master.csv')
dat$RateNorm <- (dat$RateTotal / 9.81) / 70
dat <- as_tibble(dat)
dat$PrePost <- factor(dat$PrePost, c('pre','post')) #reorder factors to plot pre before post
dat %>%
group_by(Subject, PrePost, Config) %>%
summarize(
AvgRate = mean(RateNorm),
StanceT = mean(stanceTime),
Impulse = mean(ImpulseTotal),
ImpulseHeel = mean(HeelImpulse)
) %>%
ggplot(mapping = aes(x = PrePost, y = AvgRate, fill = Config)) +
geom_bar(position="dodge", stat="identity")+ facet_wrap(~ Subject)
## Bayes
library(brms)
library(lme4)
library(tidybayes)
library(rstanarm)
lmer(dat$RateNorm ~ dat$Config + (1+ dat$Config|dat$Subject))
runmod <- brm(data = dat,
family = gaussian,
RateNorm ~ Config + (1 + Config | Subject), #fixed effect of occasion, random interecept and random slope for each subject
prior = c(prior(normal(0, 10), class = Intercept),
prior(normal(0, 1), class = b),
prior(cauchy(0, 1), class = sd),
prior(cauchy(0, 1), class = sigma),
prior(lkj_corr_cholesky(1.5), class = cor)),
iter = 2000, warmup = 1000, chains = 4, cores = 4,
control = list(adapt_delta = .975, max_treedepth = 20),
seed = 190831)
print(runmod)
posterior <- posterior_samples(runmod)
sum(posterior$b_ConfigLace > 0) / length(posterior$b_ConfigLace) #we are 92% confident lace results in a greater VLR
mean(posterior$b_ConfigLace) #The maximal a posteriori estimate is that lace increases VLR by 0.11 SD
#### Analyzing loadsol running data###
rm(list=ls())
library(tidyverse)
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Endurance Protocol Trail Run/Outdoor_Protocol_March2020/Master.csv')
#### Analyzing loadsol running data###
rm(list=ls())
library(tidyverse)
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Endurance Protocol Trail Run/Outdoor_Protocol_March2020/Master.csv')
#dat$RateNorm <- (dat$RateTotal / 9.81) / 70
dat <- as_tibble(dat)
dat$PrePost <- factor(dat$PrePost, c('pre','post')) #reorder factors to plot pre before post
dat %>%
group_by(Subject, PrePost, Config) %>%
summarize(
AvgRate = mean(RateNorm),
StanceT = mean(stanceTime),
Impulse = mean(ImpulseTotal),
ImpulseHeel = mean(HeelImpulse)
) %>%
ggplot(mapping = aes(x = PrePost, y = AvgRate, fill = Config)) +
geom_bar(position="dodge", stat="identity")+ facet_wrap(~ Subject)
#### Analyzing loadsol running data###
rm(list=ls())
library(tidyverse)
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Endurance Protocol Trail Run/Outdoor_Protocol_March2020/Master.csv')
#dat$RateNorm <- (dat$RateTotal / 9.81) / 70
dat <- as_tibble(dat)
dat$PrePost <- factor(dat$PrePost, c('pre','post')) #reorder factors to plot pre before post
dat %>%
group_by(Subject, PrePost, Config) %>%
summarize(
AvgRate = mean(RateNorm),
StanceT = mean(stanceTime),
Impulse = mean(ImpulseTotal),
ImpulseHeel = mean(HeelImpulse)
) %>%
ggplot(mapping = aes(x = PrePost, y = AvgRate, fill = Config)) +
geom_bar(position="dodge", stat="identity")+ facet_wrap(~ Subject)
ggplot(data = dat, mapping = aes(x = PrePost, y = RateNorm, fill = Config)) +
geom_boxplot() + facet_wrap(~ Subject)
## Bayes
library(brms)
library(lme4)
library(tidybayes)
library(rstanarm)
lmer(dat$RateNorm ~ dat$Config + (1+ dat$Config|dat$Subject))
#dat$RateNorm <- scale(dat$RateNorm)
plot(dat$RateNorm)
runmod <- brm(data = dat,
family = gaussian,
RateNorm ~ Config + (1 + Config | Subject), #fixed effect of occasion, random interecept and random slope for each subject
prior = c(prior(normal(0, 10), class = Intercept),
prior(normal(0, 1), class = b),
prior(cauchy(0, 1), class = sd),
prior(cauchy(0, 1), class = sigma),
prior(lkj_corr_cholesky(1.5), class = cor)),
iter = 2000, warmup = 1000, chains = 4, cores = 4,
control = list(adapt_delta = .975, max_treedepth = 20),
seed = 190831)
print(runmod)
pairs(runmod)
params <- runmod %>%
spread_draws(b_ConfigLace, sigma) %>%
posterior_summary(runmod)
posterior <- posterior_samples(runmod)
sum(posterior$b_ConfigLace > 0) / length(posterior$b_ConfigLace) #we are 92% confident lace results in a greater VLR
mean(posterior$b_ConfigLace) #The maximal a posteriori estimate is that lace increases VLR by 0.11 SD
params <- runmod %>%
spread_draws(b_ConfigLace, sigma) %>%
posterior_summary(runmod)
posterior <- posterior_samples(runmod)
sum(posterior$b_ConfigLace > 0) / length(posterior$b_ConfigLace) #we are 92% confident lace results in a greater VLR
mean(posterior$b_ConfigLace) #The maximal a posteriori estimate is that lace increases VLR by 0.11 SD
0.77/30
#extract draws corresponding to the posterior distribution
runmod %>%
spread_draws(b_ConfigLace, sigma) %>%
median_qi(b_ConfigLace, sigma)
params <- runmod %>%
spread_draws(b_ConfigLace, sigma) %>%
posterior <- posterior_samples(runmod)
dat %>%
group_by(Subject, PrePost, Config) %>%
summarize(
AvgRate = mean(RateNorm),
SDRate = sd(RateNorm),
StanceT = mean(stanceTime),
Impulse = mean(ImpulseTotal),
ImpulseHeel = mean(HeelImpulse)
) %>%
ggplot(mapping = aes(x = PrePost, y = AvgRate, fill = Config)) +
geom_bar(position="dodge", stat="identity")+ facet_wrap(~ Subject) +
geom_errorbar(aes(ymin=AvgRate-SDRate, ymax=AvgRate+SDRate), width=.2,
position=position_dodge(.9))
dat %>%
group_by(Subject, PrePost, Config) %>%
summarize(
AvgRate = mean(RateNorm),
SDRate = sd(RateNorm),
StanceT = mean(stanceTime),
SDStance = sd(stanceTime),
Impulse = mean(ImpulseTotal),
ImpulseHeel = mean(HeelImpulse)
) %>%
ggplot(mapping = aes(x = PrePost, y = StanceT, fill = Config)) +
geom_bar(position="dodge", stat="identity")+ facet_wrap(~ Subject) +
geom_errorbar(aes(ymin=AvgRate-SDRate, ymax=AvgRate+SDRate), width=.2,
position=position_dodge(.9))
dat %>%
group_by(Subject, PrePost, Config) %>%
summarize(
AvgRate = mean(RateNorm),
SDRate = sd(RateNorm),
StanceT = mean(stanceTime),
SDStance = sd(stanceTime),
Impulse = mean(ImpulseTotal),
ImpulseHeel = mean(HeelImpulse)
) %>%
ggplot(mapping = aes(x = PrePost, y = StanceT, fill = Config)) +
geom_bar(position="dodge", stat="identity")+ facet_wrap(~ Subject) +
geom_errorbar(aes(ymin=StanceT-SDStance, ymax=StanceT+SDStance), width=.2,
position=position_dodge(.9))
dat %>%
group_by(Subject, PrePost, Config) %>%
summarize(
AvgRate = mean(RateNorm),
SDRate = sd(RateNorm),
StanceT = mean(stanceTime),
SDStance = sd(stanceTime),
Impulse = mean(ImpulseTotal),
ImpulseHeel = mean(HeelImpulse),
SDHI = sd(HeelImpulse)
) %>%
ggplot(mapping = aes(x = PrePost, y = StanceT, fill = Config)) +
geom_bar(position="dodge", stat="identity")+ facet_wrap(~ Subject) +
geom_errorbar(aes(ymin=ImpulseHeel-SDHI, ymax=ImpulseHeel+SDHI), width=.2,
position=position_dodge(.9))
dat %>%
group_by(Subject, PrePost, Config) %>%
summarize(
AvgRate = mean(RateNorm),
SDRate = sd(RateNorm),
StanceT = mean(stanceTime),
SDStance = sd(stanceTime),
Impulse = mean(ImpulseTotal),
ImpulseHeel = mean(HeelImpulse),
SDHI = sd(HeelImpulse)
) %>%
ggplot(mapping = aes(x = PrePost, y = ImpulseHeel, fill = Config)) +
geom_bar(position="dodge", stat="identity")+ facet_wrap(~ Subject) +
geom_errorbar(aes(ymin=ImpulseHeel-SDHI, ymax=ImpulseHeel+SDHI), width=.2,
position=position_dodge(.9))
dat %>%
group_by(Subject, PrePost, Config) %>%
summarize(
AvgRate = mean(RateNorm),
SDRate = sd(RateNorm),
StanceT = mean(stanceTime),
SDStance = sd(stanceTime),
Impulse = mean(ImpulseTotal),
SDI = sd(ImpulseTotal),
ImpulseHeel = mean(HeelImpulse),
SDHI = sd(HeelImpulse)
) %>%
ggplot(mapping = aes(x = PrePost, y = Impulse, fill = Config)) +
geom_bar(position="dodge", stat="identity")+ facet_wrap(~ Subject) +
geom_errorbar(aes(ymin=Impulse-SDI, ymax=Impulse+SDI), width=.2,
position=position_dodge(.9))
rm(list=ls())
dat <- read_excel('C:/Users/Daniel.Feeney/Dropbox (Boa)/2018 BOA Nonlinear Segment Performance/Manuscript2/BOA 3DOF Metrics.xlsx')
# Analysis of additional DU data #
library('readxl')
library('tidyverse')
library('lme4')
library('ggplot2')
rm(list=ls())
dat <- read_excel('C:/Users/Daniel.Feeney/Dropbox (Boa)/2018 BOA Nonlinear Segment Performance/Manuscript2/BOA 3DOF Metrics.xlsx')
dat$`Subject Number` == 12
d2 <- subset(dat, dat$`Subject Number` == 12)
View(d2)
#### Analyzing loadsol running data###
rm(list=ls())
library(tidyverse)
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Endurance Protocol Trail Run/Outdoor_Protocol_March2020/Master.csv')
#dat$RateNorm <- (dat$RateTotal / 9.81) / 70
dat <- as_tibble(dat)
dat$PrePost <- factor(dat$PrePost, c('pre','post')) #reorder factors to plot pre before post
View(dat)
rm(list=ls())
library(rethinking)
library(rethinking)
data(chimpanzees)
d <- chimpanzees
d$treatment <- 1 + d$prosoc_left + 2*d$condition
xtabs( ~ treatment + prosoc_left + condition , d )
rm(list=ls())
library(rethinking)
data(chimpanzees)
d <- chimpanzees
d$treatment <- 1 + d$prosoc_left + 2*d$condition
xtabs( ~ treatment + prosoc_left + condition , d )
m11.1 <- quap(
alist(
pulled_left ~ dbinom( 1 , p ) ,
logit(p) <- a ,
a ~ dnorm( 0 , 10 ) #with an alpha only model mean 0, sd of 10
) , data=d )
set.seed(5280)
prior <- extract.prior(m11.1, n = 1e4)
## converting logit values to probability with the inverse link function
p <- inv_logit( prior$a )
dens( p , adj=0.1 )
m11.1 <- quap(
alist(
pulled_left ~ dbinom( 1 , p ) ,
logit(p) <- a ,
a ~ dnorm( 0 , 1.5) #with an alpha only model mean 0, sd of 10
) , data=d )
set.seed(5280)
prior <- extract.prior(m11.1, n = 1e4)
## converting logit values to probability with the inverse link function
p <- inv_logit( prior$a )
dens( p , adj=0.1 ) #Super bad prior- only values are at the extrememes! always or never happens
# a flat prior in the logit space is not a flat prior in probability space!
## we are interested the in the difference btetween treatments, so calculate difference for density plot
dens( abs( p[,1] - p[,2] ) , adj=0.1 )
m11.2 <- quap(
alist(
pulled_left ~ dbinom( 1 , p ) ,
logit(p) <- a + b[treatment] ,
a ~ dnorm( 0 , 1.5 ),
b[treatment] ~ dnorm( 0 , 10 )
) , data=d )
set.seed(1999)
prior <- extract.prior( m11.2 , n=1e4 )
p <- sapply( 1:4 , function(k) inv_logit( prior$a + prior$b[,k] ) ) #extract the probabiity values from inverse logit
## we are interested the in the difference btetween treatments, so calculate difference for density plot
dens( abs( p[,1] - p[,2] ) , adj=0.1 )
m11.3 <- quap(
alist(
pulled_left ~ dbinom( 1 , p ) ,
logit(p) <- a + b[treatment] ,
a ~ dnorm( 0 , 1.5 ),
b[treatment] ~ dnorm( 0 , 0.5 )
) , data=d )
set.seed(1999)
prior <- extract.prior( m11.3 , n=1e4 )
p <- sapply( 1:4 , function(k) inv_logit( prior$a + prior$b[,k] ) )
mean( abs( p[,1] - p[,2] ) )
# prior trimmed data list 11.10
dat_list <- list(
pulled_left = d$pulled_left,
actor = d$actor,
treatment = as.integer(d$treatment) )
m11.4 <- ulam(
alist(
pulled_left ~ dbinom( 1 , p ) ,
logit(p) <- a[actor] + b[treatment] ,
a[actor] ~ dnorm( 0 , 1.5 ),
b[treatment] ~ dnorm( 0 , 0.5 )
) , data=dat_list , chains=4 , log_lik=TRUE )
precis( m11.4 , depth=2 )
rm(list=ls())
library(rethinking)
data(chimpanzees)
d <- chimpanzees
d$treatment <- 1 + d$prosoc_left + 2*d$condition
xtabs( ~ treatment + prosoc_left + condition , d )
m11.1 <- quap(
alist(
pulled_left ~ dbinom( 1 , p ) ,
logit(p) <- a ,
a ~ dnorm( 0 , 10 ) #with an alpha only model mean 0, sd of 10
) , data=d )
set.seed(5280)
prior <- extract.prior(m11.1, n = 1e4)
## converting logit values to probability with the inverse link function
p <- inv_logit( prior$a )
dens( p , adj=0.1 ) #Super bad prior- only values are at the extrememes! always or never happens
# a flat prior in the logit space is not a flat prior in probability space!
m11.1 <- quap(
alist(
pulled_left ~ dbinom( 1 , p ) ,
logit(p) <- a ,
a ~ dnorm( 0 , 1.5) #with an alpha only model mean 0, sd of 10
) , data=d )
set.seed(5280)
prior <- extract.prior(m11.1, n = 1e4)
## converting logit values to probability with the inverse link function
p <- inv_logit( prior$a )
dens( p , adj=0.1 ) #Super bad prior- only values are at the extrememes! always or never happens
# a flat prior in the logit space is not a flat prior in probability space!
m11.2 <- quap(
alist(
pulled_left ~ dbinom( 1 , p ) ,
logit(p) <- a + b[treatment] ,
a ~ dnorm( 0 , 1.5 ),
b[treatment] ~ dnorm( 0 , 10 )
) , data=d )
set.seed(1999)
prior <- extract.prior( m11.2 , n=1e4 )
p <- sapply( 1:4 , function(k) inv_logit( prior$a + prior$b[,k] ) ) #extract the probabiity values from inverse logit
## we are interested the in the difference btetween treatments, so calculate difference for density plot
dens( abs( p[,1] - p[,2] ) , adj=0.1 )
m11.3 <- quap(
alist(
pulled_left ~ dbinom( 1 , p ) ,
logit(p) <- a + b[treatment] ,
a ~ dnorm( 0 , 1.5 ),
b[treatment] ~ dnorm( 0 , 0.5 )
) , data=d )
set.seed(1999)
prior <- extract.prior( m11.3 , n=1e4 )
p <- sapply( 1:4 , function(k) inv_logit( prior$a + prior$b[,k] ) )
mean( abs( p[,1] - p[,2] ) )
# prior trimmed data list 11.10
dat_list <- list(
pulled_left = d$pulled_left,
actor = d$actor,
treatment = as.integer(d$treatment) )
m11.4 <- ulam(
alist(
pulled_left ~ dbinom( 1 , p ) ,
logit(p) <- a[actor] + b[treatment] ,
a[actor] ~ dnorm( 0 , 1.5 ),
b[treatment] ~ dnorm( 0 , 0.5 )
) , data=dat_list , chains=4 , log_lik=TRUE )
precis( m11.4 , depth=2 )
post <- extract.samples(m11.4)
p_left <- inv_logit( post$a )
plot( precis( as.data.frame(p_left) ) , xlim=c(0,1) )
diffs <- list(
db13 = post$b[,1] - post$b[,3],
db24 = post$b[,2] - post$b[,4] )
plot( precis(diffs) )
m11.4 <- ulam(
alist(
pulled_left ~ dbinom( 1 , p ) ,
logit(p) <- a[actor] + b[treatment] ,
a[actor] ~ dnorm( 0 , 1.5 ),
b[treatment] ~ dnorm( 0 , 0.5 )
) , data=dat_list , chains=4 , log_lik=TRUE )
dat <- list( actor=rep(1:7,each=4) , treatment=rep(1:4,times=7) )
p_post <- link( m11.4 , data=dat )
p_mu <- apply( p_post , 2 , mean )
dat <- list( actor=rep(1:7,each=4) , treatment=rep(1:4,times=7) )
p_post <- link( m11.4 , data=dat )
p_mu <- apply( p_post , 2 , mean )
post <- extract.samples(m11.4)
mean( exp(post$b[,4]-post$b[,2]) )
data("UCBAdmissions")
d <- UCBAdmit
data("UCBAdmissions")
d <- UCBAdmit
data("UCBAdmit")
d <- UCBAdmit
data(UCBadmit)
d <- UCBadmit
dat_list <- list(
admit = d$admit,
applications = d$applications,
gid = ifelse( d$applicant.gender=="male" , 1 , 2 ) #index coding for male/female
)
m11.7 <- ulam(
alist(
admit ~ dbinom( applications , p ) ,
logit(p) <- a[gid] ,
a[gid] ~ dnorm( 0 , 1.5 )
) , data=dat_list , chains=4 )
m11.7 <- ulam(
alist(
admit ~ dbinom( applications , p ) ,
logit(p) <- a[gid] ,
a[gid] ~ dnorm( 0 , 1.5 )
) , data=dat_list , chains=4 )
precis( m11.7 , depth=2 )
data(UCBadmit)
d <- UCBadmit
library(rethinking)
library(rethinking)
data(UCBadmit)
d <- UCBadmit
dat_list <- list(
admit = d$admit,
applications = d$applications,
gid = ifelse( d$applicant.gender=="male" , 1 , 2 ) #index coding for male/female
)
m11.7 <- ulam(
alist(
admit ~ dbinom( applications , p ) ,
logit(p) <- a[gid] ,
a[gid] ~ dnorm( 0 , 1.5 )
) , data=dat_list , chains=4 )
precis( m11.7 , depth=2 )
post <- extract.samples(m11.7)
diff_a <- post$a[,1] - post$a[,2] #calcualte absolute difference
diff_p <- inv_logit(post$a[,1]) - inv_logit(post$a[,2]) #proportional difference
precis( list( diff_a=diff_a , diff_p=diff_p ) )
postcheck(m11.7)
dat_list$dept_id <- rep(1:6,each=2) #index code the departments
m11.8 <- ulam(
alist(
admit ~ dbinom( applications , p ) ,
logit(p) <- a[gid] + delta[dept_id] ,
a[gid] ~ dnorm( 0 , 1.5 ) ,
delta[dept_id] ~ dnorm( 0 , 1.5 )
) , data=dat_list , chains=4 , iter=4000 )
m11.8 <- ulam(
alist(
admit ~ dbinom( applications , p ) ,
logit(p) <- a[gid] + delta[dept_id] ,
a[gid] ~ dnorm( 0 , 1.5 ) ,
delta[dept_id] ~ dnorm( 0 , 1.5 )
) , data=dat_list , chains=4 , iter=4000 )
precis( m11.8 , depth=2 )
postcheck(m11.8)
precis( m11.8 , depth=2 )
post <- extract.samples(m11.8)
diff_a <- post$a[,1] - post$a[,2]
diff_p <- inv_logit(post$a[,1]) - inv_logit(post$a[,2])
precis( list( diff_a=diff_a , diff_p=diff_p ) )
y <- rbinom(1e5,1000,1/1000)
c( mean(y) , var(y) )
rm(list=ls())
library(rethinking)
data(reedfrogs)
d <- reedfrogs
# make the tank cluster variable
d$tank <- 1:nrow(d)
dat <- list(
S = d$surv,
N = d$density,
tank = d$tank )
# approximate posterior
m13.1 <- ulam(
alist(
S ~ dbinom( N , p ) ,
logit(p) <- a[tank] ,
a[tank] ~ dnorm( 0 , 1.5 )
), data=dat , chains=4 , log_lik=TRUE )
precis(m13.1)
precis(m13.1, depth = 2)
m13.2 <- ulam(
alist(
S ~ dbinom( N , p ) ,
logit(p) <- a[tank] ,
a[tank] ~ dnorm( a_bar , sigma ) ,
a_bar ~ dnorm( 0 , 1.5 ) ,
sigma ~ dexp( 1 )
), data=dat , chains=4 , log_lik=TRUE )
compare(m13.1, m13.2)
postcheck(m13.2)
