d <- Howell1
d <- subset(d, d$age < 18)
d <- Howell1
d <- subset(d, d$age < 18)
quap(
alist(
height ~ (mu, sigma),
quap(
alist(
height ~ (mu, sigma),
mN <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b*( weight - mean(weight) ) ,
a ~ dnorm( 138 , 20 ) ,
b ~ dlnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 50 )
) , data=d )
precis(mN)
?seq
weight.seq = seq(90, 180, length.out = 90)
sim.height <- sim(mN , data=list(weight=weight.seq) ) #simulates heights, not distributions of plausible average heights
height.PI <- apply( sim.height , 2 , PI , prob=0.89 ) #summarize these heights (get the PI for the)
mu.HPDI <- apply(sim.height, 2, HPDI, prob = 0.89) #highest desntiy posterior interval containing 89% of density
mu.PI <- apply( mu , 2 , PI , prob=0.89 ) #cmopute 89% PI at each value
mu.mean <- apply( sim.height , 2 , mean ) #compute mean of each columns (2) of mu
mu.PI <- apply( sim.height , 2 , PI , prob=0.89 ) #cmopute 89% PI at each value
plot( height ~ weight , d2 , col=col.alpha(rangi2,0.5) )
plot( height ~ weight , d , col=col.alpha(rangi2,0.5) )
lines( weight.seq , mu.mean ) # draw MAP line
shade( mu.HPDI , weight.seq )# draw HPDI region for line
# draw PI region for simulated heights
shade( height.PI , weight.seq )
weight.seq = seq(20,90, length.out = 90)
sim.height <- sim(mN , data=list(weight=weight.seq) ) #simulates heights, not distributions of plausible average heights
height.PI <- apply( sim.height , 2 , PI , prob=0.89 ) #summarize these heights (get the PI for the)
mu.HPDI <- apply(sim.height, 2, HPDI, prob = 0.89) #highest desntiy posterior interval containing 89% of density
mu.mean <- apply( sim.height , 2 , mean ) #compute mean of each columns (2) of mu
mu.PI <- apply( sim.height , 2 , PI , prob=0.89 ) #cmopute 89% PI at each value
#plotting
# plot raw data
plot( height ~ weight , d , col=col.alpha(rangi2,0.5) )
lines( weight.seq , mu.mean ) # draw MAP line
shade( mu.HPDI , weight.seq )# draw HPDI region for line
# draw PI region for simulated heights
shade( height.PI , weight.seq )
mN <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b*( weight - mean(weight) ) ,
a ~ dnorm( 138 , 20 ) ,
b ~ dlnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 50 )
) , data=d )
precis(mN)
weight.seq = seq(20,90, length.out = 70)
sim.height <- sim(mN , data=list(weight=weight.seq) ) #simulates heights, not distributions of plausible average heights
height.PI <- apply( sim.height , 2 , PI , prob=0.89 ) #summarize these heights (get the PI for the)
mu.HPDI <- apply(sim.height, 2, HPDI, prob = 0.89) #highest desntiy posterior interval containing 89% of density
mu.mean <- apply( sim.height , 2 , mean ) #compute mean of each columns (2) of mu
mu.PI <- apply( sim.height , 2 , PI , prob=0.89 ) #cmopute 89% PI at each value
#plotting
# plot raw data
plot( height ~ weight , d , col=col.alpha(rangi2,0.5) )
lines( weight.seq , mu.mean ) # draw MAP line
shade( mu.HPDI , weight.seq )# draw HPDI region for line
# draw PI region for simulated heights
shade( height.PI , weight.seq )
weight.seq = seq(-2,2, length.out = 70)
sim.height <- sim(mN , data=list(weight=weight.seq) ) #simulates heights, not distributions of plausible average heights
height.PI <- apply( sim.height , 2 , PI , prob=0.89 ) #summarize these heights (get the PI for the)
mu.HPDI <- apply(sim.height, 2, HPDI, prob = 0.89) #highest desntiy posterior interval containing 89% of density
mu.mean <- apply( sim.height , 2 , mean ) #compute mean of each columns (2) of mu
mu.PI <- apply( sim.height , 2 , PI , prob=0.89 ) #cmopute 89% PI at each value
#plotting
# plot raw data
plot( height ~ weight , d , col=col.alpha(rangi2,0.5) )
lines( weight.seq , mu.mean ) # draw MAP line
shade( mu.HPDI , weight.seq )# draw HPDI region for line
# draw PI region for simulated heights
shade( height.PI , weight.seq )
d <- Howell1
d <- subset(d, d$age < 18)
#optional, define average weight
xbar <- mean(d$weight)
lin.mod <- quap(
flist <- alist(
height ~ dnorm(mu, sigma), #general formula we expect, height depends on an unknown mu and sigma
mu <- a + b*(weight- xbar), #define the linear model alpha * beta(diff_in_weight)
a ~ dnorm(178,20), #the alpha (intercept) prior from a normal distribution with mean 178, sigma 20
b ~ dlnorm(0,1), #beta is from a log-normal distribution between 0 and 1
sigma ~ dunif(0,50) #uniform distribution (flat prior) for sigma
), data = d2
)
lin.mod <- quap(
flist <- alist(
height ~ dnorm(mu, sigma), #general formula we expect, height depends on an unknown mu and sigma
mu <- a + b*(weight- xbar), #define the linear model alpha * beta(diff_in_weight)
a ~ dnorm(178,20), #the alpha (intercept) prior from a normal distribution with mean 178, sigma 20
b ~ dlnorm(0,1), #beta is from a log-normal distribution between 0 and 1
sigma ~ dunif(0,50) #uniform distribution (flat prior) for sigma
), data = d
)
precis(lin.mod)
summary(d$weight)
weight.seq <- seq( from=4 , to=4 , by=1 )
# use link to compute mu
# for each sample from posterior
# and for each weight in weight.seq
mu <- sim(lin.mod , data=data.frame(weight=weight.seq) )
mu
# summarize the distribution of mu
mu.mean <- apply( mu , 2 , mean ) #compute mean of each columns (2) of mu
mu.PI <- apply( mu , 2 , PI , prob=0.89 ) #cmopute 89% PI at each value
plot( height ~ weight , data=d , col=col.alpha(rangi2,0.5) )
# plot the MAP line, aka the mean mu for each weight
lines( weight.seq , mu.mean )
# plot a shaded region for 89%
shade( mu.PI , weight.seq, add = TRUE )
View(d)
weight.seq <- seq( from=4 , to=40 , by=1 )
# use sim to simulate draws from posterior
mu <- sim(lin.mod , data=data.frame(weight=weight.seq) )
# use sim to simulate draws from posterior
mu <- sim(lin.mod , data=data.frame(weight=weight.seq) )
# summarize the distribution of mu
mu.mean <- apply( mu , 2 , mean ) #compute mean of each columns (2) of mu
mu.PI <- apply( mu , 2 , PI , prob=0.89 ) #cmopute 89% PI at each value
plot( height ~ weight , data=d , col=col.alpha(rangi2,0.5) )
# plot the MAP line, aka the mean mu for each weight
lines( weight.seq , mu.mean )
# plot a shaded region for 89%
shade( mu.PI , weight.seq, add = TRUE )
rm(list=ls())
data("WaffleDivorce")
d <- WaffleDivorce
# Standardize vars.Scale centers are 0 and makes SD 1
d$A <- scale(d$MedianAgeMarriage)
d$D <- scale(d$Divorce)
sd(d$MedianAgeMarriage)
m5.1 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bA * A ,
a ~ dnorm( 0 , 0.2 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
set.seed(100)
prior <- extract.prior(m5.1) #sample from the prior and link to plot over the interval [-2,2] (Standard deviation)
mu <- link( m5.1 , post=prior , data=list( A=c(-2,2) ) ) #provides
plot( NULL , xlim=c(-2,2) , ylim=c(-2,2) )
for ( i in 1:50 ) lines( c(-2,2) , mu[i,] , col=col.alpha("black",0.4) )
m5.1 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bA * A ,
a ~ dnorm( 0 , 0.2 ) ,
bA ~ dnorm( 0 , 1 ) ,
sigma ~ dexp( 1 )
) , data = d )
#Simulate from prior with extract.prior and link
set.seed(100)
prior <- extract.prior(m5.1) #sample from the prior and link to plot over the interval [-2,2] (Standard deviation)
mu <- link( m5.1 , post=prior , data=list( A=c(-2,2) ) ) #provides
plot( NULL , xlim=c(-2,2) , ylim=c(-2,2) )
for ( i in 1:50 ) lines( c(-2,2) , mu[i,] , col=col.alpha("black",0.4) )
m5.1 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bA * A ,
a ~ dnorm( 0 , 0.2 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
#Simulate from prior with extract.prior and link
set.seed(100)
prior <- extract.prior(m5.1) #sample from the prior and link to plot over the interval [-2,2] (Standard deviation)
mu <- link( m5.1 , post=prior , data=list( A=c(-2,2) ) ) #provides
plot( NULL , xlim=c(-2,2) , ylim=c(-2,2) )
for ( i in 1:50 ) lines( c(-2,2) , mu[i,] , col=col.alpha("black",0.4) )
# compute percentile interval of mean
A_seq <- seq( from=-3 , to=3.2 , length.out=30 ) #make a list of values from -3 to 3.2
mu <- link( m5.1 , data=list(A=A_seq) ) #link to that list and the model to map the parameters
mu.mean <- apply( mu , 2, mean ) #calcualte the mean over columns
mu.PI <- apply( mu , 2 , PI ) #calculate the PI over columns
# plot it all
plot( D ~ A , data=d , col=rangi2 )
lines( A_seq , mu.mean , lwd=2 )
shade( mu.PI , A_seq )
d$M <- scale( d$Marriage ) #scale marriage rate
m5.2 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bM * M , #saving bM for beta for marriage
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
precis(m5.2)
#use A_seq from previous A_seq <- seq(from = -3, to 3.2, length.out = 30)
mu <- link(m5.2, data = list(A_seq))
d$M <- scale( d$Marriage ) #scale marriage rate
m5.2 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bM * M , #saving bM for beta for marriage
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
precis(m5.2)
#use A_seq from previous A_seq <- seq(from = -3, to 3.2, length.out = 30)
mu <- link(m5.2, data = list(A_seq))
#use A_seq from previous
A_seq <- seq(from = -3, to 3.2, length.out = 30)
mu <- link(m5.2, data = list(A_seq))
#use A_seq from previous
A_seq <- seq(from = -3, to = 3.2, length.out = 30)
mu <- link(m5.2, data = list(A_seq))
mu <- link(m5.2, data = list(A= A_seq))
d$M <- scale( d$Marriage ) #scale marriage rate
m5.2 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bM * M , #saving bM for beta for marriage
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
precis(m5.2)
#use A_seq from previous
A_seq <- seq(from = -3, to = 3.2, length.out = 30)
mu <- link(m5.2, data = list(A= A_seq))
mu <- link( m5.2 , data=list(A=A_seq) )
precis(m5.2)
plot(D ~ M, data = d, col=rangi2)
mu <- link( m5.2 ,post = prior, data=list(A=A_seq) )
mu <- link(m5.2 ,post = prior, data=list(A=A_seq) )
precis(m5.2)
mu <- link( m5.2 , data=list(A=A_seq) )
mu.mean <- apply(mu, 2, mean)
mu.PI <- apply(mu, 2, PI)
plot(D ~ M, data = d, col=rangi2)
lines(A_seq,mu.mean, lwd = 2)
plot(D ~ M, data = d, col=rangi2)
lines(A_seq,mu.mean, lwd = 2)
shade(mu.PI, A_seq)
library(dagitty)
dag5.1 <- dagitty( "dag {
A -> D
A -> M
M -> D
}")
coordinates(dag5.1) <- list( x=c(A=0,D=1,M=2) , y=c(A=0,D=1,M=0) )
drawdag( dag5.1 )
dag5.2 <- dagitty( "dag {
A -> D
A -> M
}")
coordinates(dag5.2) <- list( x=c(A=0,D=1,M=2) , y=c(A=0,D=1,M=0) )
drawdag( dag5.2 )
DMA_dag2 <- dagitty('dag{ D <- A -> M }')
impliedConditionalIndependencies( DMA_dag2 )
# DAG 1
DMA_dag1 <- dagitty('dag{ D <- A -> M -> D }')
impliedConditionalIndependencies( DMA_dag1 )
m5.3 <- quap(
alist(
D ~ dnorm(mu, sigma),
mu <- a * bM*M + bA*A,
a ~ dnorm(0,0.2),
bM ~ dnorm(0,0.5),
bA ~ dnorm(0,0.5),
sigma ~ dexp(1)
), data = d
)
precis( m5.3 )
plot( coeftab(m5.1,m5.2,m5.3), par=c("bA","bM") )
m5.4 <- quap(
alist(
M ~ dnorm( mu , sigma ) ,
mu <- a + bAM * A ,
a ~ dnorm( 0 , 0.2 ) ,
bAM ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
mu <- link(m5.4)
mu_mean <- apply( mu , 2 , mean )
mu_resid <- d$M - mu_mean
# call link without specifying new data
# so it uses original data to do a posterior predictive test
mu <- link( m5.3 )
# summarize samples across cases
mu_mean <- apply( mu , 2 , mean )
mu_PI <- apply( mu , 2 , PI )
# simulate observations
# again no new data, so uses original data
D_sim <- sim( m5.3 , n=1e4 )
D_PI <- apply( D_sim , 2 , PI )
plot( mu_mean ~ d$D , col=rangi2 , ylim=range(mu_PI) ,
xlab="Observed divorce" , ylab="Predicted divorce" )
abline( a=0 , b=1 , lty=2 )
for ( i in 1:nrow(d) ) lines( rep(d$D[i],2) , mu_PI[,i] , col=rangi2 )
identify( x=d$D , y=mu_mean , labels=d$Loc )
plot( mu_mean ~ d$D , col=rangi2 , ylim=range(mu_PI) ,
xlab="Observed divorce" , ylab="Predicted divorce" )
abline( a=0 , b=1 , lty=2 )
for ( i in 1:nrow(d) ) lines( rep(d$D[i],2) , mu_PI[,i] , col=rangi2 )
identify( x=d$D , y=mu_mean , labels=d$Loc )
data(WaffleDivorce) 5.19
data(WaffleDivorce)
d <- list()
d$A <- standardize( WaffleDivorce$MedianAgeMarriage )
d$D <- standardize( WaffleDivorce$Divorce )
d$M <- standardize( WaffleDivorce$Marriage )
m5.3_A <- quap(
alist(
## A -> D <- M
D ~ dnorm( mu , sigma ) ,
mu <- a + bM*M + bA*A ,
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 ),
## A -> M
M ~ dnorm( mu_M , sigma_M ),
mu_M <- aM + bAM*A,
aM ~ dnorm( 0 , 0.2 ),
bAM ~ dnorm( 0 , 0.5 ),
sigma_M ~ dexp( 1 )
) , data = d )
precis(m5.3_A)
A_seq <- seq( from=-2 , to=2 , length.out=30 ) #Z scores [-2, 2]
sim_dat <- data.frame( A=A_seq )
s <- sim( m5.3_A , data=sim_dat , vars=c("M","D") )
plot( sim_dat$A , colMeans(s$D) , ylim=c(-2,2) , type="l" ,
xlab="manipulated A" , ylab="counterfactual D" )
shade( apply(s$D,2,PI) , sim_dat$A )
mtext( "Total counterfactual effect of A on D" )
data("Howell1")
d <- Howell1
mu_female <- rnorm(1e4,178,20)
mu_male <- rnorm(1e4,178,20) + rnorm(1e4,0,10)
precis( data.frame( mu_female , mu_male ) )
d$sex <- ifelse( d$male==1 , 2 , 1 )
# approximate the posterior using index variables
m5.8 <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a[sex] ,
a[sex] ~ dnorm( 178 , 20 ) ,
sigma ~ dunif( 0 , 50 )
) , data=d )
precis( m5.8 , depth=2 )
post <- extract.samples(m5.8)
post$diff_fm <- post$a[,1] - post$a[,2]
precis( post , depth=2 )
data("milk")
d <- milk
#coerce to integer for index variables
d$clade_id <- as.integer( d$clade )
d$K <- scale( d$kcal.per.g ) 5.51
d$K <- scale( d$kcal.per.g )
m5.9 <- quap(
alist(
K ~ dnorm(mu, sigma),
mu <- a[clade_id],
a[clade_id] ~ dnorm(0,0.5),
sigma ~ dexp(1)
), data = d
)
labels <- paste( "a[" , 1:4 , "]:" , levels(d$clade) , sep="" )
plot( precis( m5.9 , depth=2 , pars="a" ) , labels=labels ,
xlab="expected kcal (std)" )
## adding in another category
set.seed(63)
d$house <- sample( rep(1:4,each=8) , size=nrow(d) )
m5.10 <- quap(
alist(
K ~ dnorm( mu , sigma ),
mu <- a[clade_id] + h[house],
a[clade_id] ~ dnorm( 0 , 0.5 ),
h[house] ~ dnorm( 0 , 0.5 ),
sigma ~ dexp( 1 )
) , data=d )
precis(m5.10, depth = 4)
### linear mixed models with a Bayesian interpretation ##
library(brms)
library(tidyverse)
library(haven) #Data lib. 405 children elementary school measured over 4 periods on different reading/math scores
setwd('C:/Users/Daniel.Feeney/Documents/BayesianDecisionAnalysis')
curran_dat <- read_sav("CurranLong.sav") %>%
select(id, occasion, read, homecog) %>%
filter(complete.cases(.))
curran_dat
read1 <- brm(data = curran_dat,
family = gaussian,
formula = read ~ 1 + (1 | id),
prior = c(prior(normal(0, 10), class = Intercept),
prior(cauchy(0, 1), class = sd),
prior(cauchy(0, 1), class = sigma)),
iter = 2000, warmup = 1000, chains = 4, cores = 4,
control = list(adapt_delta = .975, max_treedepth = 20),
seed = 190831)
print(read1)
# population level intervcept is 4.11 with a Bayesian credible interval of 4.01-4.21.
# Estimate of SD(intercept) is 0.54, meaning there is high interpersonal variability
plot(read1)
#look at model against random sample
set.seed(25)
curran_dat %>%
bind_cols(as_tibble(fitted(read1))) %>%
group_by(id) %>%
nest() %>%
sample_n(6) %>%
unnest() %>%
ggplot() +
geom_point(aes(x = occasion, y = read), size = 4, alpha = .75, color = "dodgerblue2") +
geom_point(aes(x = occasion, y = Estimate), shape = 1, size = 4, stroke = 1.5) +
labs(x = "Assessment Period",
y = "Reading Ability",
title = "Model 1: One Random Effect, No Covariates",
subtitle = "Blue points are observed values. Black circles are fitted values.") +
scale_x_continuous(expand = c(.075, .075), breaks = 0:3) +
facet_wrap(~id, nrow = 1) +
theme_bw(base_size = 14) +
theme(plot.title = element_text(hjust = .5))
bind_cols(as_tibble(fitted(read1)))
bind_cols(as_tibble(fitted(read1))) %>%
group_by(id)
# now let's add a random effect for assessment. Adding a second random effect (1|occasion)
read2 <- brm(data = curran_dat,
family = gaussian,
read ~ 1 + (1 | id) + (1 | occasion),
prior = c(prior(normal(0, 10), class = Intercept),
prior(cauchy(0, 1), class = sd),
prior(cauchy(0, 1), class = sigma)),
iter = 2000, warmup = 1000, chains = 4, cores = 4,
control = list(adapt_delta = .975, max_treedepth = 20),
seed = 190831)
print(read2) #we have significantly reduced the overall sigma, which is the goal of these models by resolving overall sigma into cluster-level variance
plot(read2)
curran_dat %>%
ggplot(aes(x = occasion, y = read, group = id)) +
geom_line(size = .75, alpha = .20) +
labs(x = "Assessment Period",
y = "Reading Ability") +
theme_minimal(base_size = 16)
# fixed effects model for occasion and random for id. beta needs a new prior so we choose normal (0,1).
read3 <- brm(data = curran_dat,
family = gaussian,
read ~ 1 + occasion + (1 | id),
prior = c(prior(normal(0, 10), class = Intercept),
prior(normal(0, 1), class = b),
prior(cauchy(0, 1), class = sd),
prior(cauchy(0, 1), class = sigma)),
iter = 2000, warmup = 1000, chains = 4, cores = 4,
control = list(adapt_delta = .975, max_treedepth = 20),
seed = 190831)
print(read3)
plot(read3)
read4 <- brm(data = curran_dat,
family = gaussian,
read ~ 1 + occasion + (1 + occasion | id), #fixed effect of occasion, random interecept and random slope for each subject
prior = c(prior(normal(0, 10), class = Intercept),
prior(normal(0, 1), class = b),
prior(cauchy(0, 1), class = sd),
prior(cauchy(0, 1), class = sigma),
prior(lkj_corr_cholesky(1.5), class = cor)),
iter = 2000, warmup = 1000, chains = 4, cores = 4,
control = list(adapt_delta = .975, max_treedepth = 20),
seed = 190831)
print(read4)
plot(read4)
library(lme4)
lmer(curran_dat$read ~ occasion + (1 + occasion | id))
lmer(curran_dat$read ~ curran_dat$occasion + (1 + curran_dat$occasion | curran_dat$id))
# Try on some pilot data
dat <- read.csv('C:/Users/Daniel.Feeney/Dropbox (Boa)/Endurance Protocol Trail Run/Outdoor_Protocol_March2020/Master.csv')
dat$RateNorm <- (dat$RateTotal / 9.81) / 70
dat <- subset(dat, dat$Subject != 'SH') #removing the incomplete case
dat <- as_tibble(dat)
dat$PrePost <- factor(dat$PrePost, c('pre','post')) #reorder factors to plot pre before post
lmer(dat$RateNorm ~ dat$Config + (1|dat$Subject))
lmer(dat$RateNorm ~ dat$Config + (1+ dat$Config|dat$Subject))
runmod <- brm(data = curran_dat,
family = gaussian,
RateNorm ~ Config + (1 + Config | Subject), #fixed effect of occasion, random interecept and random slope for each subject
prior = c(prior(normal(0, 10), class = Intercept),
prior(normal(0, 1), class = b),
prior(cauchy(0, 1), class = sd),
prior(cauchy(0, 1), class = sigma),
prior(lkj_corr_cholesky(1.5), class = cor)),
iter = 2000, warmup = 1000, chains = 4, cores = 4,
control = list(adapt_delta = .975, max_treedepth = 20),
seed = 190831)
runmod <- brm(data = dat,
family = gaussian,
RateNorm ~ Config + (1 + Config | Subject), #fixed effect of occasion, random interecept and random slope for each subject
prior = c(prior(normal(0, 10), class = Intercept),
prior(normal(0, 1), class = b),
prior(cauchy(0, 1), class = sd),
prior(cauchy(0, 1), class = sigma),
prior(lkj_corr_cholesky(1.5), class = cor)),
iter = 2000, warmup = 1000, chains = 4, cores = 4,
control = list(adapt_delta = .975, max_treedepth = 20),
seed = 190831)
print(runmod)
plot(runmod)
print(runmod)
plot(runmod)
